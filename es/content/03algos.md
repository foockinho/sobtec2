# El código es político, los algoritmos son armas matemáticas de destrucción [^1]

***Benjamin Cadon***

![](../../contrib/gfx/illustrations/algoritmos-halfsize.png)

Se escucha mucho hablar de ellos, pero jamás se los ve. ¿Qué son esos
algoritmos, estas criaturas invisibles e inasequibles que se deslizan en
nuestros cerebros y habitan en nuestros bolsillos? ¿Qué propósitos los animan?

Desde un punto de vista formal, un algoritmo no es más que una inofensiva
seguidilla de operaciones alimentada por los datos y que produce un
resultado. Sin embargo, ellos automatizan la resolución de un conjunto de
problemas complejos [^2]; y es así que algunos se transforman en Inteligencias
Artificiales avanzadas, gracias a empresas que las atiborran con los datos que
les entregamos amable y gratuitamente.

## Un bestiario [^3] de algoritmos

No hay nada como saber de qué se alimentan para identificar y comprender
mejor su papel en la sociedad de los humanos informatizados. Ellos no
nacieron de una chispa eléctrica en el fondo de un mar de sulfurosos
datos. Sus progenitores son los seres humanos, quienes escriben las
líneas de código para realizar un programa portador de un proyecto
político y societal dictado por un patrocinador público o privado. Estos
algoritmos nunca son «neutros» e imparciales, y se centran en realizar
la misión que les ha sido asignada, con frecuencia por occidentales de
género masculino procedentes de las clases altas acunadas por el
capitalismo.

Es necesario mencionar también que un algoritmo tonto alimentado con
muchos buenos datos conseguirá mayores éxitos que una famosa
Inteligencia Artificial, y esto, aunque ésta tenga las garras afiladas.
Cómo no citar estos ogros americanos que son los GAFAM (Google, Apple,
Facebook, Amazon y Microsoft) o BATX para sus alter egos en China
(Baidu, Alibaba, Tencent y Xiaomi). Su metabolismo está basado en el
hecho de recolectar, con nuestra ayuda, un máximo de datos sobre
nuestros más pequeños actos y gestos, «aumentando» nuestro cotidiano con
un gran número de aplicaciones móviles y de objetos conectados,
supuestamente, para hacer más fáciles nuestras vidas.

### Quienes comen nuestros datos personales

Los algoritmos resultantes son polimorfos. En primer lugar ellos han
crecido observándonos desde lejos, espiando nuestra actividad en las
redes, los lugares que más frecuentamos. Se elevan a continuación por
encima de nuestras interacciones con el objetivo de determinar mejor
quien hace autoridad, pasando de la lógica del voto popular hacia una
clasificación basada en el mérito.

En un tercer movimiento, se adentran en nuestra intimidad digital
analizando la calidad y la frecuencia de nuestros intercambios para
evaluar nuestra reputación y para rastrear nuestras afinidades. Por
último se esconden de nuestra mirada para predecir mejor el menor de
nuestros deseos, y poder condicionarlos.

| | **A un lado** | **Por encima** | **Dentro** | **Por debajo** |
| --- | --- | --- | ---| --- |
| **Ejemplos** | Medición de audiencia, Google Analytics, pestañas de publicitarias | Google PageRank, Digg, Wikipedia  | Número de amigos en Facebook, Retweets de Twitter, notas y opiniones | Recomendaciones de Amazon, behaviour publicidad comportamentales | 
| **Datos** | Visitas | Relación | Likes | Huellas/Rastos |
| **Población** | Muestras representativas | Voto censitario, comunidades | Redes sociales, declarativo | Implicit Comportamientos individuales implícitos |
| **Fórma de cálculo** | Voto | Clasificación por mérito | Benchmark | Machine Learning |
| **Principio** | Popularidad | Autoridad | Reputación | Predicción | 

*Tabla de Dominique Cardon en «À quoi rêvent les algorithmes» [^4] (¿Con
qué sueñan los algoritmos?)*

Estas diferentes generaciones de algoritmos conviven juntas y son
fácilmente reconocibles debido a que son muy eficaces en brindarnos
muchos servicios, siempre y cuando paguemos nuestro «dividendo
digital» [^5], ya que discretizan nuestra existencia, rebanándola en
lonchas tan finas como sea posible para extraer toda información [^6]
monetizable.

Cada Estado cría a un ogro horrible que trabaja en temas de
inteligencia. Sus propios intereses se enfrentan con frecuencia con los
de sus amigos ogros comerciantes, pero estos lo dejan hurtar dentro de
sus despensas [^7]. Su apetito insaciable le lleva a estar, a menudo, al
acecho allí donde transitan un gran volumen de los datos. Se supone que
debería poder encontrar un terrorista en un pajar, aunque sufre a menudo
de miopía y de obesidad, es más eficaz robando secretos políticos e
industriales que cogiendo a los malos antes de que pasen a la acción.

### Quienes comen los datos públicos

Los diferentes estratos administrativos de la fuerza pública cultivan
igualmente jardines florecientes de datos de sabores variados:
biométricos, fiscales, medioambientales, urbanos, profesionales o
incluso relacionados con la salud.

En apariencia neutrales y objetivas, las criaturas algorítmicas públicas
serían la solución a las desigualdades en el trato causadas por el libre
arbitrio de algunos funcionarios. Sin embargo, ellas pueden transformar
a familias enteras en insectos kafkianos colgados de la máquina de
escribir de la película *Brazil* [^8]. Actualmente, son ellas las que
determinan a qué escuela debe asistir su hijo, si pueden beneficiar de
ayudas sociales, a qué trabajo debe aplicar, o en qué momento del ciclo
menstrual podrán procrear.

Los comerciantes de los datos personales proponen amablemente su ayuda a
las organismos públicos para digitalizar y clonar las más bellas plantas
de su jardín público, ya se traten de flores culturales o de hierbas
medicinales. Como los comerciantes, la fuerza pública también esta
evolucionando de la observación a la predicción, no solamente para
optimizar la recogida de basura, sino también para enviar las fuerzas
policiales allí donde un delito tiene mayor probabilidad de ser
cometido. Todo gracias a algoritmo-perros como PredPol CompStat o
HunchLab [^9].

### Quienes comen el dinero

Thomas Peterffy es un financiero que se dedicó a remplazar los agentes
de bolsa y sus operaciones manuales por máquinas automatizadas. En 1987,
constatando que el número de órdenes pasadas por Peterffy era
sorprendentemente elevado, los responsables de los mercados enviaron a
un inspector. Este esperaba encontrar una sala de mercados repleta de
hombres vociferando y sudando, pero sólo encontró un ordenador IBM
conectado a una terminal oficial del Nasdaq [^10]. Así fue como los
algoritmos se lanzaron a los mercados financieros.

Hoy en día, el *algotrading* (*trading* con algoritmos) se ha
generalizado, y los parpadeos algorítmicos serenos de las redes
informáticas han remplazado a los corredores de bolsa *(traders)*
neuróticos. Pero estas criaturas digitales de la finanzas se han visto
sobrepasado por los algotraders de alta frecuencias. Estos se
desplazan a la velocidad de la luz, construyendo caminos para llegar a
la orden de compra y venta más rápidamente que los otros [^11], y
consiguen así un beneficio en cada operación. Se cobijan dentro de los
numerosos «*dark pools*» que los bancos han creado gracias a la
relajación paradójica de las reglamentaciones. En ese confort lucrativo
interrumpido a veces por «Flash Crashs» [^12], aumenta la diversidad de
especies algorítmicas (Blast, Stealth, Sniffer, Iceberg, Shark,
Sumo [^13]) al mismo tiempo que la complejidad de sus estrategias,
volviendo los «mercados» cada vez más ilegibles e incontrolables aunque
se supone que se regulan a golpe de manos invisibles.

Todo esto impacta en lo que llamamos «la economía real», es decir, la
vida de la gente. Por ejemplo, cuando piratas informáticos sirios toman
el control de la cuenta de Twitter de la Casa Blanca y mandan un tuit
alarmista, este es inmediatamente leído por los robots *algotraders*,
haciendo caer la bolsa en picado a alturas de 136 mil millones de
dólares en 3 minutos [^14].

En la jungla de las finanzas, otra criatura algorítmica con la forma de
un gusano se duplica en todos los ordenadores receptores y engorda al
ritmo de su utilización, devorando a su paso una cantidad impresionante
de electricidad [^15]. Se llama la «*blockchain*» [^16] y se desarrolló a
partir del «*bitcoin*», la primera crypto-moneda que no necesita un
organismo bancario central ligado a un Estado. El bitcoin vale hoy 28
mil millones de dólares [^17].

Por suerte, iniciativas como Ethereum [^18] han permitido a estos gusanos
poder mutar para no solamente registrar transacciones, sino también
transportar bases de datos y aplicaciones «inteligentes» (los «*smart*
contratos»). Esto impulsa proyectos como la DAO [^19] (Decentralized
Autonomous Organisation), un fondo de inversión descentralizado sin
directorio donde cada persona toma parte de las decisiones en función de
su capital. Este fondo consiguió rápidamente 150 mil millones de dólares
de diferentes inversores.

Sin embargo, un personaje algo travieso consiguió sustraer un tercio de
este capital explotando una vulnerabilidad (él lo definió como una
funcionalidad) del código grabado en el cuerpo del gusano DAO alojado
por Ethereum. ¿Qué hacer?¿Cortar algunos de los anillos del gusano
enfermo o matarlo para crear uno nuevo? Aunque los inversores parten del
principio libertario según el cual «el código hace la ley», optaron por
la segunda solución para que los inversores recuperasen su dinero. Esto
plantea importantes cuestiones legales, particularmente a la hora de
definir las responsabilidades en una red descentralizada [^20] o imaginar
formas de gobernanza para este «código» que suplanta en ciertos dominios
las leyes de los Estados.

Otras criaturas algorítmicas son aficionadas al dinero y buscan
reemplazar el trabajo humano, maximizando la productividad y los costos;
y contribuyendo así a una mayor concentración de capitales. Las grandes
empresas lo han entendido muy bien, y es así que Foxconn anuncia el
remplazo de la casi totalidad de sus empleados por un millón de
robots [^21] y el gabinete de abogados BakerHostetler contrata a ROSS una
inteligencia artificial para estudiar más rápidamente los complejos
legajos jurídicos [^22]. La «muerte del trabajo» ha sido declarada [^23]
pero el régimen económico y social que debería sustituirlo tarda en
aparecer.

### Quienes comen los cerebros humanos

Las últimas variedades identificadas dentro de nuestro bestiario
algorítmico son aquellas cuya voluntad es llenar el cerebro humano y
aquellas que, por el contrario, aspiran a remplazarlo. Las inteligencias
artificiales deben nutrirse con buenos datos para poder suplantar a los
humanos dentro de un gran número de procesos. Es lo que hace Google con
su proyecto reCAPTCHA [^24], esas imágenes que debemos descifrar y
transcribir para hacer comprender al servidor que no somos robots, sino
humanos, pasando así a la inversa el test de Turing  [^25]. La gran
innovación de reCAPTCHA, es que el fruto de nuestras respuestas nutre
directamente las inteligencias artificiales de los programas de Google:
descifrado de texto para mejorar la digitalización de libros,
identificación de los números de edificios para afinar la cartografía y
ahora, identificación de imágenes que contienen animales o carteles de
señalización para hacer que el piloto automático de los automóviles sean
menos miopes. Acumulados, los resultados se vuelven cada vez más
pertinentes representando millones de horas de trabajo humano [^26].

En lo que se refiere al algoritmo que contribuye a nutrir nuestro
cerebro, este es como su colega recolector de datos personales, cada vez
más elaborado y sutil. Alimentamos su cerebro cotidianamente con la
ayuda de un motor de búsqueda que nos indicará el lugar más pertinente,
la información más precisa, el vídeo más emblemático. En 2017, en el
92,8 % de los casos se trata de Google. Esto lo transforma en un
dictador cultural con una posición hegemónica completamente inusitada
(pero, ¡¿qué hacen las autoridades reguladoras de la competencia?!). No
aparecer en los primeros resultados es como no existir. Sin embargo, el
algoritmo de búsqueda de Google es un secreto industrial celosamente
guardado y sólo puede ser contrarrestado con el derecho al olvido [^27].

La experiencia surrealista realizada en 2010, durante las elecciones del
congreso de EE.UU, sobre 61 millones de usuarios, por los investigadores
del laboratorio de Facebook [^28], demostró que el control de los
mensajes de movilización política tiene una influencia directa sobre el
voto de las personas, así como el de sus amigos y amigos de amigos.
Ahora que, las “noticias falsas” remplazan las verdaderas y engrosan la
flota de la posverdad, podemos preguntarnos ¿a qué bando político
pertenecen los algoritmos que deciden las publicaciones que aparecen en
nuestros «muros»?

Los problemas de acoso y discursos de odio en estas plataformas, colocan
a los algoritmos y sus diseñadores en la posición de censores morales de
gran parte de la sociedad.

Se podría pensar que para alcanzar más rápidamente el punto de
singularidad tecnológica [^29], nuestras criaturas digitales agazapadas
en la sombra se las ingenian para volvernos serviles.

La gobernabilidad algorítmica [^30] sería ese nuevo modo de gobierno de
las conductas, fruto de deslizamientos en nuestra relación con el otro,
el grupo, el mundo, con el sentido mismo de las cosas, gracias o a pesar
de un giro digital. Todo ello conlleva repercusiones fundamentales sobre
la manera cómo se fabrican las normas y la obediencia [^31].

Cuando un algoritmo come del cerebro humano, esto puede provocar también
su muerte clínica. Qué decir de los algoritmos que predefinen las
víctimas de los drones asesinos piloteados a distancia por seres
humanos. ¿Cómo los algoritmos de un automóvil sin conductor escogen el
menor mal/número de muertos cuando están implicados en un accidente? La
ciberguerra vuela rasante sobre nuestras conexiones a la red, y cada
país afila sus algoritmos para volverse cada vez más insidiosamente
peligrosos que los de sus enemigos.

## ¿Cómo saber si un algoritmo es malo o bueno?

¿Algoritmo malo, aquel que transformó las cámaras de videovigilancia en
un ejército de botnets sanguinarios que se precipitan en masa para
estrangular servidores? ¿Algoritmo bueno, aquel que me recuerda el
aniversario de mis amigos? No es tan simple formular estos criterios
considerando la interdependencia entre algoritmo, datos y las
intenciones que los rigen. No obstante, se puede esperar que un
algoritmo bueno responda a lo siguiente:

-   Ser «abierto» y alimentarse exclusivamente de datos abiertos («*open
    data*»), completos y «cosechables» por otros, e idealmente también
    poder discriminar su acceso para volverse de pago para ciertos
    usos comerciales.
-   Ser «auditable» y por lo tanto constituido por un código de fuente
    abierto y documentado.

    Ser «leal y justo» para no provocar discriminaciones o injusticias
    (sociales [^32], de género [^33], etc), ni hacer daño a los seres
    humanos [^34].

-   Ser «transparente [^35]» y capaz de realizar auditorías sistemáticas
    acerca de sus operaciones y evoluciones. En el caso de que esté
    dotado de capacidades de aprendizaje o de predicción, debe someterse
    a controles ciudadanos.
-   Ser «alterable» para de forma legítima responder a las reclamaciones
    que puedan engendrar modificaciones en su funcionamiento.

En esta búsqueda de una moral y ética algorítmica, también es necesario
mencionar las API (*Application Programming Interface*), quienes permiten que
las criaturas digitales vayan cazando datos de otros servidores y
servicios, o por el contrario que puedan colocar contenidos o cebos.
Estas API suelen usar patente de software anti código abierto
permitiendo a sus propietarios abrir o cerrar a discreción sus puertas.
También pueden implementar un peaje cuando el tráfico de un algoritmo se
vuelve abundante y su monetización se vuelve oportuna.

En el ámbito del sector público y de la sociedad civil, podemos imaginar
que los criterios de apertura, transparencia, responsabilidad,
modificabilidad sean algún día aplicados y respetados. Pero para el
sector privado/comercial resulta más complicado imaginarse tal cosa ya
que los datos y los algoritmos se han vuelto «el petróleo del
futuro» [^36]...

De la misma manera, un grupo de investigadores americanos y algunas
grandes empresas de lo digital han intentado formular los «principios
para unos algoritmos responsables». Se han reunido para iniciar un
proceso sobre la ética de las Inteligencias Artificiales [^37], y
comunicar a los políticos y ciudadanos preocupados que ellos «anticipan
y administran» esta complejidad con buenos resultados y que realmente no
es útil legislar.

Sin embargo, la cuestión no trata de exigir transparencia del código de
los algoritmos, sino de sus objetivos y motivaciones [^38]. Para
animarnos podemos citar el debate participativo en Francia sobre la «Ley
de la república digital» que ha llevado a instituir un deber de
transparencia para los algoritmos utilizados por las instituciones
públicas [^39], o referir a la iniciativa «TransAlgo» [^40] de l’INRIA que
aspira a evaluar la responsabilidad y la transparencia de los programas
robots.

## Futurutopías algorítmicas soberanas

Entonces, ¿cómo pasar de una bestia algorítmica a un algoritmo que
alimentamos como un animal de compañía? ¿Compostamos algunas lombrices
para dibujar las ramificaciones biotecnológicas que conducirán a los
hombres y a la tecnología a vivir en una armonía de silicio? ¿Cómo
podemos volver a tomar en nuestras manos nuestros destinos, nuestra
autonomía mental, nuestra soberanía tecnológica hoy en día propulsada
algorítmicamente en el espacio del control social?

El código es un objeto político, todo como este mundo «digital» repleto
de *algobots* que se introducen en nuestras realidades.

En calidad de objetos políticos, podemos por lo tanto atacarlos con
herramientas clásicas: militancia y *lobbying *didáctico ante los
poderes públicos, tentativas para influir y ahondar en los procesos
reglamentarios, valorización de las iniciativas que dan mayor autonomía
y felicidad a los seres humanos. Igualmente oportuno, reivindicar un
lugar más importante de la sociedad civil dentro de las instancias de
regulación y de normalización de Internet, la adopción de un estándar
por una tecnología de red [^41] teniendo, por ejemplo, el equivalente a
un articulo para la constitución de un país.

A nivel individual, es necesario sin duda alguna «desgooglizar»
Internet [^42], es decir, como lo que propone la asociación Framasoft,
apoyarse en los alojamientos de servicios autónomos, transparentes,
abiertos, neutros y solidarios (cf. iniciativa CHATONS [^43]), o por qué
no autoalojar sus datos en un mini servidor poco ambicioso. Se puede,
también, probar el camuflaje utilizando el cifrado de extremo a extremo,
lo que no es siempre adaptable, ni adoptable (PGP y los correos
electrónicos). Según las situaciones se puede tener recursos de
interferencias intentando hacer desaparecer el dato «verdadero» dentro
de datos ficticios pero creíbles que un algoritmo cómplice nos puede
proveer en abundancia.

Del lado de los poderes públicos, queda mucho trabajo por hacer, la vía
hacia la transparencia ética está trazada, sólo falta empujarlas hacia
allí con firmeza. Por supuesto, si hay que adoptar un corte de pelo y un
maquillaje [^44] extraño para escapar a los sistemas de reconocimiento
facial [^45], del fichaje biométrico, de la vinculación de las bases de
datos públicas, y las derivas digitales del estado de urgencia, todo
ello nos invita a no meter todos nuestros bytes en una misma cesta.

También se puede tomar partido por nutrir estos «algoIAs» con basura.
Como hicieron algunos usuarios de Twitter quienes consiguieron en menos
de un día transformar la IA de Microsoft TAY en una entidad sexista,
racista y pro-Hitler [^46]…Mejor criar pequeños «algoponis» quienes, con
una ondulación de sus crines multicolores sobre un fondo de prados de
datos, nos recordarían que «¡la amistad es mágica!».

Cursilerías a parte, quizás sea también necesario proponer un
intermediario informático, un «proxy» entre nosotros, nuestros datos y
los actores públicos y privados que los acogen. Este intermediario
podría alojar confortablemente a Eliza [^47], mi inteligencia artificial
estrictamente personal que se nutre de mis actividades y de mis
preferencias para ayudarme de la mejor manera a compartir mis datos y
contenidos. Sea en el anonimato, sea entregándolos a los organismos
públicos en una lógica de interés general, sea cifrándolos o
escondiéndolos para seguir hablando con mis amigos que no llegaron a
salir de las redes sociales comerciales.

Distribuidas en el bolsillos de cada uno, las IA personales podrían
volverse simbióticas, con el acuerdo de sus tutores, y contar a la
humanidad micro-ficciones adaptadas a su contexto político y cultural,
con el propósito de construir realidades armoniosas dónde cohabitarán en
paz los algoritmos, los humanos, la naturaleza y el mundo inorgánico.

[^1]: Este título hace referencia al libro de Cathy O’Neil. *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*. Crown, 6 de septiembre de 2016.

[^2]: En esta novela futurista de Isaac Asimov, Estados Unidos se han convertido a una «democracia electrónica» donde el ordenador Multivac selecciona una sola persona para responder a una serie de preguntas. Multivac utilizará las respuestas y otros datos para determinar cuáles serían los resultados de una elección, evitando la necesidad de que se realice una elección real: https://en.wikipedia.org/wiki/Franchise_%28short_story%29

[^3]: https://fr.wikipedia.org/wiki/Bestiaire

[^4]: Dominique Cardon: *A quoi rêvent les algorithmes? Nos vies à l’heure – Nos vies à l’heure des big data*. Le Seuil, 2015.

[^5]: Evgeny Morozov, y Pascale Haas: Le mirage numérique – Pour une politique du Big Data. Les Prairies Ordinaires, 2015.

[^6]: http://centenaire-shannon.cnrs.fr/chapter/la-theorie-de-information

[^7]: https://fr.wikipedia.org/wiki/PRISM_(programme_de_surveillance)

[^8]: Terry Gilliam: *Brazil*. 1985. http://www.imdb.com/title/tt0088846/

[^9]: Cathy O’Neil: *Weapons of Math Destruction – How Big Data Increases Inequality and Threatens Democracy. Crown, 6 de septiembre de 2016.

[^10]: Unos días más tarde, el inspector le ordena a Peterfly que ingrese las órdenes tecleando manualmente en la terminal y le otorgan una semana para desconectar la IBM. En este lapso de tiempo, contratará a ingenieros y construirá una cámara de ojo capaz de leer la pantalla, que envía información al cerebro de IBM a la que ha injertado manos electromecánicas que pueden teclear las órdenes a toda velocidad en la terminal Nasdaq.

[^11]: Sniper In Mahwah: Anthropology, market structure & the nature of exchanges: https://sniperinmahwah.wordpress.com/

[^12]: El Flash Crash del 6 mayo de 2010 analizado por Nanex: http://www.nanex.net/20100506/FlashCrashAnalysis_Intro.html y https://www.youtube.com/watch?v=E1xqSZy9_4I

[^13]: Alexandre Laumonier. *5/6*. Zones Sensibles Editions, 2014. http://www.zones-sensibles.org/livres/6-5/

[^14]: https://www.washingtonpost.com/news/worldviews/wp/ 2013/04/23/syrian-hackers-claim-ap-hack-that-tipped-stock-market-by-136billion-is-it-terrorism/

[^15]: Esta criatura es tan costosa (una operación le demanda tanta electricidad como un hogar americano medio en un día y medio), que vive principalmente en China y ahora es muy lenta: http://motherboard.vice.com/read/bitcoin-isunsustainable

[^16]: https://marmelab.com/blog/2016/04/28/blockchain-for-web-developers-the-theory.html

[^17]: Capitalización y movimientos cotidianos de las crypto-monedas: http://coinmarketcap.com/

[^18]: https://www.ethereum.org/

[^19]: https://en.wikipedia.org/wiki/The_DAO_(organization)

[^20]: Primavera De Filippi (Berkman Center Fellow): Ethereum – Freenet or Skynet?: https://cyber.harvard.edu/events/luncheon/2014/04/difilippi

[^21]: http://www.theverge.com/2016/12/30/14128870/foxconn-robotsautomation-apple-iphone-china-manufacturing

[^22]: https://www.washingtonpost.com/news/innovations/wp/2016/05/16/meet-ross-the-newly-hired-legal-robot/

[^23]: Bernard Stiegler: *La Société automatique – L'avenir du travail*. Fayard, 2015. http://www.philomag.com/les-livres/fiche-de-lecture/la-societeautomatique-1-lavenir-du-travail-11454

[^24]: https://www.google.com/recaptcha/intro/index.html

[^25]: https://en.wikipedia.org/wiki/Turing_test

[^26]: http://www.bizjournals.com/boston/blog/techflash/2015/01/massachusetts-womans-lawsuit-accuses-google-of.html

[^27]: https://www.google.com/webmasters/tools/legal-removal-request?complaint_type=rtbf

[^28]: A 61-million-person experiment in social influence and political mobilization: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3834737/

[^29]: https://fr.wikipedia.org/wiki/Singularité_technologique

[^30]: Antoinette Rouvroy y Thomas Berns: Gouvernementalité algorithmique et perspectives d'émancipation – Le disparate comme condition d'individuation par la relation? Politique des algorithmes. Les métriques du web. *RESEAUX*, Vol.31, n.177, pp. 163-196, 2013. http://works.bepress.com/antoinette_rouvroy/47/

[^31]: ifapa.me es un colectivo dedicado a la investigación y en subvertir los efectos de la matematizacióna y cuantificación de la vida diaria en la sociedades necrocapitalista: http://www.ifapa.me/

[^32]: https://www.washingtonpost.com/opinions/big-data-may-bereinforcing-racial-bias-in-the-criminal-justice-system/2017/02/10/d63de518ee3a-11e6-9973-c5efb7ccfb0d_story.html?utm_term=.b7f5ab5df1f9

[^33]: https://www.genderit.org/feminist-talk/algorithmic-discrimination-andfeminist-politics

[^34]: https://fr.wikipedia.org/wiki/Trois_lois_de_la_robotique

[^35]: http://internetactu.blog.lemonde.fr/2017/01/21/peut-on-armer-la-transparence-de-linformation/

[^36]: Documental *Le secret des 7 soeurs*: http://secretdes7soeurs.blogspot.fr/

[^37]: http://www.lemonde.fr/pixels/article/2016/09/28/intelligence-artificielle-les-geants-du-web-lancent-un-partenariatsur-l-ethique_5005123_4408996.html

[^38]: http://www.internetactu.net/2016/03/16/algorithmes-etresponsabilites/

[^39]: https://www.service-public.fr/particuliers/actualites/A11502

[^40]: https://www-direction.inria.fr/actualite/actualites-inria/transalgo

[^41]: The Internet Engineering Task Force (IETF ®): http://www.ietf.org/

[^42]: http://degooglisons-internet.org/

[^43]: https://chatons.org/

[^44]: https://cvdazzle.com/

[^45]: http://www.lemonde.fr/pixels/article/2016/10/19/inquietudes-autourde-la-reconnaissance-faciale-aux-etats-unis_5016364_4408996.html

[^46]: https://www.theguardian.com/technology/2016/mar/24/tay-microsoftsai-chatbot-gets-a-crash-course-in-racism-from-twitter

[^47]: http://elizagen.org
